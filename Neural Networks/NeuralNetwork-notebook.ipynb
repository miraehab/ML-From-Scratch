{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mirae\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the features (pixel values) and labels from the dataset\n",
    "X = mnist.data.values.astype('float32')\n",
    "y = mnist.target.values.astype('int64')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Standardize the data:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a small epsilon value to add to the standard deviation to avoid division by zero\n",
    "eps = 1e-8\n",
    "\n",
    "# Calculate the standard deviation of each feature and replace any zero values with eps\n",
    "std_dev = np.std(X, axis=0)\n",
    "std_dev[std_dev == 0] = eps\n",
    "\n",
    "# Normalize the data by subtracting the mean and dividing by the standard deviation\n",
    "X = (X - np.mean(X, axis=0)) / std_dev"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Divide data into training and test:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dynamic Neural Network Implementation:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(input_size, output_size)\n",
    "        self.bias = np.random.randn(1, output_size)\n",
    "\n",
    "    def feed_forward(self, input):\n",
    "        self.input = input\n",
    "          \n",
    "        return np.dot(self.input, self.weights) + self.bias\n",
    "    \n",
    "    def backpropagation(self, output_gradient, learning_rate):\n",
    "        # output_gradient = dE/dY \n",
    "        # dE/dW = (dE/dY)*X.T\n",
    "        dw = np.dot(self.input.T, output_gradient)\n",
    "        self.weights -= learning_rate*dw\n",
    "        # dE/dB = dE/dY(output_gradient)\n",
    "        self.bias -= learning_rate*output_gradient\n",
    "        # dE/dX = W.T*(dE/dY)(output_gradient)\n",
    "        return np.dot(output_gradient, self.weights.T)\n",
    "    \n",
    "class Activation(Layer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def feed_forward(self, input):\n",
    "        self.input = input\n",
    "        return sigmoid(self.input)\n",
    "    \n",
    "    def backpropagation(self, output_gradient, learning_rate):\n",
    "        return sigmoid_prime(self.input)*output_gradient\n",
    "\n",
    "def sigmoid(linear_pred):\n",
    "    return (1 / (1 + np.exp(-linear_pred)))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x)*(1- sigmoid(x)) \n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    squared_error = np.square(np.subtract(y_true, y_pred))\n",
    "\n",
    "    return squared_error.mean()\n",
    "\n",
    "def mse_prime(y_true, y_pred):\n",
    "    return(2*(y_pred-y_true)/y_true.size)\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, num_of_layers, size_of_layers, epochs = 1000, learning_rate = 0.1):\n",
    "        self.num_of_layers = num_of_layers\n",
    "        self.size_of_layers = size_of_layers\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.network = []\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        self.network = []\n",
    "        last_output = X.shape[1]\n",
    "        for i in range(self.num_of_layers):\n",
    "            # We initialize every layer with the input size which is equal to the output of the previous layer\n",
    "            self.network.append(Layer(last_output, self.size_of_layers[i]))\n",
    "            last_output = self.size_of_layers[i]\n",
    "            self.network.append(Activation())\n",
    "\n",
    "        for i in range(self.epochs):\n",
    "            error = 0\n",
    "            for x, y in zip(X, Y):\n",
    "                ### Feed Forward ###\n",
    "                output = x\n",
    "                output = output.reshape((1, x.shape[0]))\n",
    "                \n",
    "                for layer in self.network:\n",
    "                    output = layer.feed_forward(output)\n",
    "                    if output.shape[0] != 1: \n",
    "                        output = np.transpose(output)\n",
    "\n",
    "                # Calculate the error for each sample\n",
    "                error += mse(y, output)\n",
    "\n",
    "                ### Backpropagation ###\n",
    "                output_gradient = mse_prime(y, output)\n",
    "                for layer in reversed(self.network):\n",
    "                    output_gradient = layer.backpropagation(output_gradient, self.learning_rate)\n",
    "\n",
    "            error /= X.shape[0]\n",
    "\n",
    "            print(\"{}/{} loss: {} \".format(i+1, self.epochs, error))\n",
    "\n",
    "    def predict(self, X):\n",
    "        output_result = []\n",
    "        for x in X:\n",
    "            output = x\n",
    "            output = output.reshape((1, x.shape[0]))\n",
    "            for layer in self.network:\n",
    "                output = layer.feed_forward(output)\n",
    "                if output.shape[0] != 1: \n",
    "                    output = np.transpose(output)\n",
    "            \n",
    "            output_result.append(output)\n",
    "\n",
    "        return output_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y):\n",
    "    return np.sum((y_pred == y))/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>NN with only 2 layers => 1 hidden layer and 1 output layer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn1 = NN(num_of_layers = 2, size_of_layers =[20, 10], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirae\\AppData\\Local\\Temp\\ipykernel_24112\\858757348.py:35: RuntimeWarning: overflow encountered in exp\n",
      "  return (1 / (1 + np.exp(-linear_pred)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/50 loss: 0.07327014354635457 \n",
      "2/50 loss: 0.0449111279610398 \n",
      "3/50 loss: 0.0342251433359864 \n",
      "4/50 loss: 0.02902979230249089 \n",
      "5/50 loss: 0.026027144899373154 \n",
      "6/50 loss: 0.023981029060812727 \n",
      "7/50 loss: 0.02248376744531853 \n",
      "8/50 loss: 0.021354027809687263 \n",
      "9/50 loss: 0.02044767336678559 \n",
      "10/50 loss: 0.01970549328035553 \n",
      "11/50 loss: 0.01907641668105688 \n",
      "12/50 loss: 0.018518856108391973 \n",
      "13/50 loss: 0.018039045430829348 \n",
      "14/50 loss: 0.017605674733962337 \n",
      "15/50 loss: 0.017218574784650584 \n",
      "16/50 loss: 0.016864691675553246 \n",
      "17/50 loss: 0.016551501329355862 \n",
      "18/50 loss: 0.016266715609448017 \n",
      "19/50 loss: 0.01598969656479519 \n",
      "20/50 loss: 0.01574587181083787 \n",
      "21/50 loss: 0.015534482951133568 \n",
      "22/50 loss: 0.015325277484819322 \n",
      "23/50 loss: 0.015130464131561378 \n",
      "24/50 loss: 0.01494469593967693 \n",
      "25/50 loss: 0.014769446719160731 \n",
      "26/50 loss: 0.014572559853752005 \n",
      "27/50 loss: 0.014402282563260456 \n",
      "28/50 loss: 0.014248388750981339 \n",
      "29/50 loss: 0.0141036482776228 \n",
      "30/50 loss: 0.013968360484645824 \n",
      "31/50 loss: 0.013841038729489911 \n",
      "32/50 loss: 0.013708886863151953 \n",
      "33/50 loss: 0.013591934744460054 \n",
      "34/50 loss: 0.013474947913975134 \n",
      "35/50 loss: 0.013365797198537309 \n",
      "36/50 loss: 0.013258292165418888 \n",
      "37/50 loss: 0.013159604230985342 \n",
      "38/50 loss: 0.013067443130120045 \n",
      "39/50 loss: 0.012973560025780111 \n",
      "40/50 loss: 0.012886999100856911 \n",
      "41/50 loss: 0.01280032814416245 \n",
      "42/50 loss: 0.0127191570865214 \n",
      "43/50 loss: 0.012635103275676105 \n",
      "44/50 loss: 0.012572181343749426 \n",
      "45/50 loss: 0.01249094402723087 \n",
      "46/50 loss: 0.01242576482163937 \n",
      "47/50 loss: 0.012363162167389764 \n",
      "48/50 loss: 0.012295212854083264 \n",
      "49/50 loss: 0.012236789186116993 \n",
      "50/50 loss: 0.012177931070331023 \n"
     ]
    }
   ],
   "source": [
    "nn1.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirae\\AppData\\Local\\Temp\\ipykernel_24112\\858757348.py:35: RuntimeWarning: overflow encountered in exp\n",
      "  return (1 / (1 + np.exp(-linear_pred)))\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = nn1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels1 = np.ravel(np.argmax(y_pred1, axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8965"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc1 = accuracy(predicted_labels1, y_test)\n",
    "accuracies[\"NN with 2 layers\"] = acc1\n",
    "acc1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>NN with 3 layers=> 2 hidden layers</h3>\n",
    "<h5># of neurons in first layer < # of neurons in second layer</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn2 = NN(num_of_layers = 3, size_of_layers =[20, 30, 10], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirae\\AppData\\Local\\Temp\\ipykernel_24112\\858757348.py:35: RuntimeWarning: overflow encountered in exp\n",
      "  return (1 / (1 + np.exp(-linear_pred)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/50 loss: 0.07105491334390256 \n",
      "2/50 loss: 0.04138520963462935 \n",
      "3/50 loss: 0.030785621260748467 \n",
      "4/50 loss: 0.02571909991615781 \n",
      "5/50 loss: 0.022913192383723347 \n",
      "6/50 loss: 0.021139536799921293 \n",
      "7/50 loss: 0.019838436926637906 \n",
      "8/50 loss: 0.018849824557446233 \n",
      "9/50 loss: 0.018025017940869446 \n",
      "10/50 loss: 0.017353957487981218 \n",
      "11/50 loss: 0.016797284830442363 \n",
      "12/50 loss: 0.016323427389784873 \n",
      "13/50 loss: 0.015892885928703273 \n",
      "14/50 loss: 0.015498518751479026 \n",
      "15/50 loss: 0.015154556107462348 \n",
      "16/50 loss: 0.014831187738860357 \n",
      "17/50 loss: 0.014524998782623142 \n",
      "18/50 loss: 0.014257289878065531 \n",
      "19/50 loss: 0.013994553952003524 \n",
      "20/50 loss: 0.013759504588459301 \n",
      "21/50 loss: 0.013550606170606815 \n",
      "22/50 loss: 0.013353094443944339 \n",
      "23/50 loss: 0.01316042516549546 \n",
      "24/50 loss: 0.01298872594264445 \n",
      "25/50 loss: 0.012813461319130803 \n",
      "26/50 loss: 0.012632635692051945 \n",
      "27/50 loss: 0.01246434622091689 \n",
      "28/50 loss: 0.01232331058688973 \n",
      "29/50 loss: 0.012182501401092807 \n",
      "30/50 loss: 0.012043067821742304 \n",
      "31/50 loss: 0.01190656823017494 \n",
      "32/50 loss: 0.01178470161750483 \n",
      "33/50 loss: 0.011665783354370195 \n",
      "34/50 loss: 0.011552268573059247 \n",
      "35/50 loss: 0.011448016723015078 \n",
      "36/50 loss: 0.011344140276635668 \n",
      "37/50 loss: 0.011243045748056475 \n",
      "38/50 loss: 0.011146341533195884 \n",
      "39/50 loss: 0.011055870149183987 \n",
      "40/50 loss: 0.010964333299967573 \n",
      "41/50 loss: 0.010885056411151044 \n",
      "42/50 loss: 0.010802832158434953 \n",
      "43/50 loss: 0.01073116980270942 \n",
      "44/50 loss: 0.010654480561605938 \n",
      "45/50 loss: 0.01058003005692442 \n",
      "46/50 loss: 0.010516182834173679 \n",
      "47/50 loss: 0.01045001685200802 \n",
      "48/50 loss: 0.010389568178062731 \n",
      "49/50 loss: 0.010329204619641305 \n",
      "50/50 loss: 0.010270518783290689 \n"
     ]
    }
   ],
   "source": [
    "nn2.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirae\\AppData\\Local\\Temp\\ipykernel_24112\\858757348.py:35: RuntimeWarning: overflow encountered in exp\n",
      "  return (1 / (1 + np.exp(-linear_pred)))\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = nn2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels2 = np.ravel(np.argmax(y_pred2, axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8982142857142857"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc2 = accuracy(predicted_labels2, y_test)\n",
    "accuracies[\"NN with 3 layers (#1st layer < #2nd layer)\"] = acc2\n",
    "acc2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>NN with 3 layers=> 2 hidden layers</h3>\n",
    "<h5># of neurons in first layer > # of neurons in second layer</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn3 = NN(num_of_layers = 3, size_of_layers =[30, 20, 10], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirae\\AppData\\Local\\Temp\\ipykernel_24112\\858757348.py:35: RuntimeWarning: overflow encountered in exp\n",
      "  return (1 / (1 + np.exp(-linear_pred)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/50 loss: 0.07639697446015814 \n",
      "2/50 loss: 0.04730401247335965 \n",
      "3/50 loss: 0.03242271740186554 \n",
      "4/50 loss: 0.02694724371553464 \n",
      "5/50 loss: 0.02375423153931089 \n",
      "6/50 loss: 0.021541144481008172 \n",
      "7/50 loss: 0.01993157443712929 \n",
      "8/50 loss: 0.018670080536234087 \n",
      "9/50 loss: 0.017656549840873385 \n",
      "10/50 loss: 0.016837744427874026 \n",
      "11/50 loss: 0.0161586735910201 \n",
      "12/50 loss: 0.015587390436058425 \n",
      "13/50 loss: 0.015092295503989456 \n",
      "14/50 loss: 0.014651974178703788 \n",
      "15/50 loss: 0.014266481663385622 \n",
      "16/50 loss: 0.01391415854386508 \n",
      "17/50 loss: 0.013593892944592791 \n",
      "18/50 loss: 0.013293634114018214 \n",
      "19/50 loss: 0.013017935414982409 \n",
      "20/50 loss: 0.012775219325890097 \n",
      "21/50 loss: 0.012546267964237237 \n",
      "22/50 loss: 0.012323464250346356 \n",
      "23/50 loss: 0.012109956525952622 \n",
      "24/50 loss: 0.011912346429453755 \n",
      "25/50 loss: 0.011731813155955846 \n",
      "26/50 loss: 0.011560556735306222 \n",
      "27/50 loss: 0.011398318918539504 \n",
      "28/50 loss: 0.011249122100109235 \n",
      "29/50 loss: 0.011108663411473756 \n",
      "30/50 loss: 0.01097316199616569 \n",
      "31/50 loss: 0.010843284761593259 \n",
      "32/50 loss: 0.010722182067393664 \n",
      "33/50 loss: 0.010609465554601297 \n",
      "34/50 loss: 0.010500607982977526 \n",
      "35/50 loss: 0.010395728264667661 \n",
      "36/50 loss: 0.010292661906400876 \n",
      "37/50 loss: 0.010194794081677082 \n",
      "38/50 loss: 0.010099391814567274 \n",
      "39/50 loss: 0.010006483491708585 \n",
      "40/50 loss: 0.009916962224555074 \n",
      "41/50 loss: 0.009827902104202018 \n",
      "42/50 loss: 0.009739568612347546 \n",
      "43/50 loss: 0.009654873898483811 \n",
      "44/50 loss: 0.009574707233241138 \n",
      "45/50 loss: 0.009500073953305495 \n",
      "46/50 loss: 0.009430298212440956 \n",
      "47/50 loss: 0.009359983593756583 \n",
      "48/50 loss: 0.009288251716510591 \n",
      "49/50 loss: 0.009216612461399227 \n",
      "50/50 loss: 0.009153638433001425 \n"
     ]
    }
   ],
   "source": [
    "nn3.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mirae\\AppData\\Local\\Temp\\ipykernel_24112\\858757348.py:35: RuntimeWarning: overflow encountered in exp\n",
      "  return (1 / (1 + np.exp(-linear_pred)))\n"
     ]
    }
   ],
   "source": [
    "y_pred3 = nn3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels3 = np.ravel(np.argmax(y_pred3, axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8981428571428571"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc3 = accuracy(predicted_labels3, y_test)\n",
    "accuracies[\"NN with 3 layers (#1st layer > #2nd layer)\"] = acc3\n",
    "acc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NN with 2 layers': 0.8965,\n",
       " 'NN with 3 layers (#1st layer < #2nd layer)': 0.8982142857142857,\n",
       " 'NN with 3 layers (#1st layer > #2nd layer)': 0.8981428571428571}"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
